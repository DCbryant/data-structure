斐波那契数列的定义如下：

- 1和2的斐波那契数是1

- n(n > 2) 的斐波那契数是 (n-1)的斐波那契数 + n(n-2)的斐波那契数

假设需要计算数字6的斐波那契值，则计算过程如下图：

![](https://user-gold-cdn.xitu.io/2017/6/26/9e9f5f313f02f8fdb49eec96e1adb96d?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## 动态规划

动态规划(Dynamic Programming，DP)是一种将复杂问题分解成更小的子问题来解决的优化技术。

上面提到过几次动态规划技术。用动态规划解决的一个问题是图搜索中的深度优先搜索。要注意动态规划和分而治之（归并排序和快速排序算法中用到的那种）是不同的方法。分而治之方法是把问题分解成相互独立的子问题，然后组合它们的答案，而动态规划则是将问题分解成相互依赖的子问题。另一个例子是上一节解决的斐波那契问题。我们将斐波那契问题分解成如该节图示的小问题。

用动态规划解决问题时，要遵循三个重要步骤：

1. 定义子问题

2. 实现要反复执行而解决子问题的部分（可能是递归）

3. 识别并求解出边界条件

能用动态规划解决的一些著名的问题如下：

- 背包问题：给出一组项目，各自有值和容量，目标是找出总值最大的项目的集合。这个问题的限制是，总容量必须小于等于“背包”的容量

- 最长公共子序列：找出一组序列的最长公共子序列（可由另一序列删除元素但不改变余下元素的顺序而得到）

- 矩阵链相乘：给出一系列矩阵，目标是找到这些矩阵相乘的最高效办法(计算次数尽可能少)，相乘操作不会进行，解决方案是找到这些矩阵各自相乘的顺序

- 硬币找零：给出面额为 d1...dn 的一定数量的硬币和要找零的钱数，找出有多少种找零的方法
图的全源最短路径：对所有顶点对(u, v)，找出从顶点u到顶点v的最短路径。

接下来的例子，涉及硬币找零问题的一个变种。

最少硬币找零问题是硬币找零问题的一个变种。硬币找零问题是给出要找零的钱数，以及可 用的硬币面额 d1...dn 及其数量，找出有多少种找零方法。最少硬币找零问题是给出要找零的钱数， 以及可用的硬币面额 d1...dn 及其数量，找到所需的最少的硬币个数。

例如，美国有以下面额(硬币）：d1=1, d2=5, d3=10, d4=25，如果要找36美分的零钱，我们可以用1个25美分、1个10美分和1个便士（ 1美分)。

如何将这个解答转化成算法？

最少硬币找零的解决方案是找到 n 所需的最小硬币数。但要做到这一点，首先得找到对每个 x < n 的解。然后，我们将解建立在更小的值的解的基础上。

## 贪心算法

贪心算法遵循一种近似解决问题的技术，期盼通过每个阶段的局部最优选择（当前最好的解），从而达到全局的最优(全局最优解)。它不像动态规划那样计算更大的格局。

最少硬币找零问题也能用贪心算法解决。大部分情况的结果是最优的，不过对有些面额而言， 结果不会是最优的。

比起动态规划算法而言，贪心算法更简单、更快。然而，如我们所见，它并不总是得到最优 答案。但是综合来看，它相对执行时间来说，输出了一个可以接受的解。

## 大0表示法

大O表示法的概念。是描述算法的性能和复杂程度。

分析算法时，时常遇到以下几类函数：

|符号   |名称   |
|-------|------|
|O(1)|常数的|
|O(log(n))|对数的|
|O((log(n))c)|对数多项式的|
|O(n)|线性的|
|O(n²)|二次的|
|O(n^c)|多项式的|
|O(c^n)|指数的|


如何衡量算法的效率？通常是用资源，例如CPU (时间）占用、内存占用、硬盘占用和网络占用。当讨论大0表示法时，一般考虑的是CPU (时间）占用。

### O(1)

考虑以下函数：

```javascript
function increment (num) {
    return ++num
}
```

假设运行increment函数，执行时间等于X。如果再用不同的参数运行一次 increment 函数，执行时间依然是X。和参数无关，increment 函数的性能都一样。因此，我们 说上述函数的复杂度是 0(1)(常数)。

### O(n)

```javascript
Array.prototype.sequentialSearch = function(item) {
    for (let i = 0; i < this.length; i++) {
        if (item === this[i]) return i
    }
    return -1
}
```

如果将含10个元素的数组[1, ..., 10]传递给该函数，假如搜索1这个元素，那么，第一次判断时就能找到想要搜索的元素。在这里我们假设每执行一次循环，开销是1。

现在，假如要搜索元素11。循环会执行10次（遍历数组中所有的值，并且找不到要搜索的 元素，因而结果返回-1)。如果一次循环的开销是1，那么它执行10次的开销就是10, 10倍于第一种假设。

现在，假如该数组有1000个元素（[1, ..., 1000])。搜索1001的结果是循环执行了1000次，然后返回-1。

注意，sequentialSearch 函数执行的总开销取决于数组元素的个数（数组大小），而且也和搜索的值有关。如果是查找数组中存在的值，循环会执行几次呢？如果查找的是数组中不存在的值，那么循环就会执行和数组大小一样多次，这就是通常所说的最坏情况。

最坏情况下，如果数组大小是10，开销就是10；如果数组大小是1000，开销就是1000。可以 得出 sequentialSearch 函数的时间复杂度是 O(n)，n是输人数组的大小


### O(n²)

```javascript
Array.prototype.bubbleSort = function() {
    for (let i = 0; i < this.length; i++) {
        for (let j = 0; j < this.length - 1 - i; j++) {
            if (this[j] > this[j + 1]) {
                let aux = this[j]
                this[j] = this[j + 1]
                this[j + 1] = aux
            }
        }
    }
}
```

如果用大小为10的数组执行 bubbleSort，开销是100(10²)。如果用大小为100的数组执行 bubbleSort,开销就是 10000(100²)。我们每次增加输人的大小，执行都会越来越久。

时间复杂度 O(n) 的代码只有一层循环，而 O(n²) 的代码有双层嵌套循环；如果算法有三层遍历数组的嵌套循环，它的时间复杂度很可能就是 O(n^3)。

下图比较了前述各个大O符号表示的时间复杂度：

![时间复杂度](https://user-gold-cdn.xitu.io/2017/6/26/87b09b0861cf4596ccc240f32a8235f2?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## 数据结构相关算法复杂度

下表是常用的数据结构算法插人、删除和搜索操作的时间复杂度：

![算法复杂度](https://user-gold-cdn.xitu.io/2017/6/26/418be9230bb45d16436b4476540725e6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## 图算法复杂度

下表分别列出了使用表示图的两种方式时，图的存储空间大小，及其增加顶点、增加边、删除顶点、删除边、查找顶点的时间复杂度：

![图算法复杂度](https://user-gold-cdn.xitu.io/2017/6/26/ac255e2c8c67bfe42ddd67ea03c72342?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)


## 排序算法复杂度

以下是排序算法在最好、一般和最差的情况下的时间复杂度:

![排序算法复杂度](https://user-gold-cdn.xitu.io/2017/6/26/1c0d89f77fd70c21910229bd68857de5?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

搜索算法复杂度

以下是搜索算法的时间复杂度，包括图的遍历算法：

![搜索算法复杂度](https://user-gold-cdn.xitu.io/2017/6/26/83f1dad22cff06ee59df054a80e12633?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

